{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":471747,"sourceType":"datasetVersion","datasetId":3660}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nimport spacy\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nimport re,string,unicodedata\nimport pickle\n\nfrom tqdm import tqdm\nimport seaborn as sns\n\nimport gensim","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:33:10.746961Z","iopub.execute_input":"2024-05-11T14:33:10.747964Z","iopub.status.idle":"2024-05-11T14:33:10.762083Z","shell.execute_reply.started":"2024-05-11T14:33:10.747931Z","shell.execute_reply":"2024-05-11T14:33:10.761158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:33:31.264391Z","iopub.execute_input":"2024-05-11T14:33:31.264757Z","iopub.status.idle":"2024-05-11T14:33:31.269827Z","shell.execute_reply.started":"2024-05-11T14:33:31.264727Z","shell.execute_reply":"2024-05-11T14:33:31.268789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/news-of-the-site-folhauol/articles.csv\",encoding=\"utf8\")","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:33:31.646915Z","iopub.execute_input":"2024-05-11T14:33:31.647460Z","iopub.status.idle":"2024-05-11T14:33:45.424999Z","shell.execute_reply.started":"2024-05-11T14:33:31.647430Z","shell.execute_reply":"2024-05-11T14:33:45.423931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:33:45.426631Z","iopub.execute_input":"2024-05-11T14:33:45.426934Z","iopub.status.idle":"2024-05-11T14:33:45.437425Z","shell.execute_reply.started":"2024-05-11T14:33:45.426909Z","shell.execute_reply":"2024-05-11T14:33:45.436155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:33:45.438944Z","iopub.execute_input":"2024-05-11T14:33:45.439361Z","iopub.status.idle":"2024-05-11T14:33:45.467811Z","shell.execute_reply.started":"2024-05-11T14:33:45.439331Z","shell.execute_reply":"2024-05-11T14:33:45.467000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:33:45.469911Z","iopub.execute_input":"2024-05-11T14:33:45.470166Z","iopub.status.idle":"2024-05-11T14:33:45.475485Z","shell.execute_reply.started":"2024-05-11T14:33:45.470144Z","shell.execute_reply":"2024-05-11T14:33:45.474563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df[\"title\"][0],\"\\n\",df[\"text\"][0])","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:33:45.476487Z","iopub.execute_input":"2024-05-11T14:33:45.476805Z","iopub.status.idle":"2024-05-11T14:33:45.484507Z","shell.execute_reply.started":"2024-05-11T14:33:45.476783Z","shell.execute_reply":"2024-05-11T14:33:45.483630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Linhas:',len(df))\ndf.drop_duplicates(subset=[\"text\"],inplace=True)\nprint('Removendo duplicadas em \"text\":',len(df))\ndf.drop(['subcategory','link','date'],axis=1,inplace=True)\nprint('Removendo subcategory')\ndf.dropna(inplace=True)\nprint('Removendo nulos:',len(df))\ndf.reset_index(drop=True,inplace=True)\nprint('Resetando index')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:33:45.485532Z","iopub.execute_input":"2024-05-11T14:33:45.485823Z","iopub.status.idle":"2024-05-11T14:33:45.996366Z","shell.execute_reply.started":"2024-05-11T14:33:45.485801Z","shell.execute_reply":"2024-05-11T14:33:45.995493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop = set(stopwords.words('portuguese'))\npunctuation = list(string.punctuation)\nstop.update(punctuation)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:33:45.997469Z","iopub.execute_input":"2024-05-11T14:33:45.997758Z","iopub.status.idle":"2024-05-11T14:33:46.011561Z","shell.execute_reply.started":"2024-05-11T14:33:45.997734Z","shell.execute_reply":"2024-05-11T14:33:46.010718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing URL's\ndef remove_urls(text):\n    return re.sub(r'http\\S+', '', text)\n\n#Removing the stopwords from text\ndef remove_stopwords(text):\n    final_text = []\n    for i in text.split():\n        if i.strip().lower() not in stop:\n            final_text.append(i.strip())\n    return \" \".join(final_text)\n\n# https://stackoverflow.com/questions/34293875/how-to-remove-punctuation-marks-from-a-string-in-python-3-x-using-translate/34294022\ndef remove_punct(text):\n    translator = str.maketrans(\"\", \"\", string.punctuation)\n    return text.translate(translator)\n\n#Removing the noisy text\ndef denoise_text(text):\n    text = remove_urls(text)\n    text = remove_stopwords(text)\n    text = remove_punct(text)\n    return text\n\n#Apply function on review column\ndf['text']=df['text'].apply(denoise_text)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:33:46.012567Z","iopub.execute_input":"2024-05-11T14:33:46.012869Z","iopub.status.idle":"2024-05-11T14:34:52.137370Z","shell.execute_reply.started":"2024-05-11T14:33:46.012845Z","shell.execute_reply":"2024-05-11T14:34:52.136374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df[\"title\"][0],\"\\n\",df[\"text\"][0])","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:34:52.138380Z","iopub.execute_input":"2024-05-11T14:34:52.138674Z","iopub.status.idle":"2024-05-11T14:34:52.143985Z","shell.execute_reply.started":"2024-05-11T14:34:52.138645Z","shell.execute_reply":"2024-05-11T14:34:52.143198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:36:48.975834Z","iopub.execute_input":"2024-05-11T14:36:48.976207Z","iopub.status.idle":"2024-05-11T14:36:48.986608Z","shell.execute_reply.started":"2024-05-11T14:36:48.976179Z","shell.execute_reply":"2024-05-11T14:36:48.985724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_style(\"dark\")\nsns.countplot(y='category', data=df)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:36:54.939256Z","iopub.execute_input":"2024-05-11T14:36:54.939966Z","iopub.status.idle":"2024-05-11T14:36:55.763619Z","shell.execute_reply.started":"2024-05-11T14:36:54.939933Z","shell.execute_reply":"2024-05-11T14:36:55.762715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Contar a frequência de cada categoria\ncategoria_counts = df['category'].value_counts()\n\n# Pegar as 7 categorias mais frequentes\ntop_7_categorias = categoria_counts.index[:7]\n\n# Defina todas as categorias que não estão entre as 7 mais frequentes como 'outros'\ndf.loc[~df['category'].isin(top_7_categorias), 'category'] = 'outros'","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:37:02.275617Z","iopub.execute_input":"2024-05-11T14:37:02.276301Z","iopub.status.idle":"2024-05-11T14:37:02.315918Z","shell.execute_reply.started":"2024-05-11T14:37:02.276269Z","shell.execute_reply":"2024-05-11T14:37:02.315150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_style(\"dark\")\nsns.countplot(y='category', data=df)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:37:03.799398Z","iopub.execute_input":"2024-05-11T14:37:03.800155Z","iopub.status.idle":"2024-05-11T14:37:04.293217Z","shell.execute_reply.started":"2024-05-11T14:37:03.800117Z","shell.execute_reply":"2024-05-11T14:37:04.292304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:37:35.619763Z","iopub.execute_input":"2024-05-11T14:37:35.620437Z","iopub.status.idle":"2024-05-11T14:37:35.626226Z","shell.execute_reply.started":"2024-05-11T14:37:35.620407Z","shell.execute_reply":"2024-05-11T14:37:35.625338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:37:36.427263Z","iopub.execute_input":"2024-05-11T14:37:36.428004Z","iopub.status.idle":"2024-05-11T14:37:36.433188Z","shell.execute_reply.started":"2024-05-11T14:37:36.427977Z","shell.execute_reply":"2024-05-11T14:37:36.432328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calcular o número de palavras em cada texto\nword_counts = [len(str(text).split()) for text in df['text']]\n\n# Encontrar o número máximo de palavras\nmax_words = max(word_counts)\n\n# Encontrar o número mínimo de palavras\nmin_words = min(word_counts)\n\nprint('Número máximo de palavras:', max_words)\nprint('Número mínimo de palavras:', min_words)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:37:40.235272Z","iopub.execute_input":"2024-05-11T14:37:40.235987Z","iopub.status.idle":"2024-05-11T14:37:44.086156Z","shell.execute_reply.started":"2024-05-11T14:37:40.235954Z","shell.execute_reply":"2024-05-11T14:37:44.085081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## WORD2VEC MODEL USING GENSIM","metadata":{}},{"cell_type":"code","source":"df.reset_index(drop=True, inplace=True)\n\narticles_tokens=[]\nfor i in range(len(df[\"text\"])):\n    articles_tokens.append([word for word in word_tokenize(str(df[\"text\"][i].lower())) if len(word)>2])","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:38:32.111129Z","iopub.execute_input":"2024-05-11T14:38:32.111469Z","iopub.status.idle":"2024-05-11T14:46:07.216424Z","shell.execute_reply.started":"2024-05-11T14:38:32.111445Z","shell.execute_reply":"2024-05-11T14:46:07.215427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"articles_tokens[0][0:10]","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:46:07.218001Z","iopub.execute_input":"2024-05-11T14:46:07.218278Z","iopub.status.idle":"2024-05-11T14:46:07.224501Z","shell.execute_reply.started":"2024-05-11T14:46:07.218255Z","shell.execute_reply":"2024-05-11T14:46:07.223624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save, load =  False, True\nif save: \n    # Salvar articles_tokens como um arquivo pickle\n    with open('articles_tokens.pkl', 'wb') as f:\n        pickle.dump(articles_tokens, f)\nif load:\n    # Carregar articles_tokens de um arquivo pickle\n    with open('articles_tokens.pkl', 'rb') as f:\n        articles_tokens = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T15:14:02.609034Z","iopub.execute_input":"2024-05-11T15:14:02.609857Z","iopub.status.idle":"2024-05-11T15:14:10.618493Z","shell.execute_reply.started":"2024-05-11T15:14:02.609829Z","shell.execute_reply":"2024-05-11T15:14:10.617482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dimension of vectors we are generating\nEMBEDDING_DIM = 100","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:48:46.671406Z","iopub.execute_input":"2024-05-11T14:48:46.672071Z","iopub.status.idle":"2024-05-11T14:48:46.676019Z","shell.execute_reply.started":"2024-05-11T14:48:46.672038Z","shell.execute_reply":"2024-05-11T14:48:46.675113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wv_model = gensim.models.Word2Vec(sentences=articles_tokens, \n                                  min_count=5, \n                                  vector_size=EMBEDDING_DIM, \n                                  workers=4)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:48:49.215321Z","iopub.execute_input":"2024-05-11T14:48:49.215969Z","iopub.status.idle":"2024-05-11T14:51:51.417065Z","shell.execute_reply.started":"2024-05-11T14:48:49.215937Z","shell.execute_reply":"2024-05-11T14:51:51.416027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wv_model.save('word2vec_v2.model')","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:52:08.947141Z","iopub.execute_input":"2024-05-11T14:52:08.947799Z","iopub.status.idle":"2024-05-11T14:52:09.083066Z","shell.execute_reply.started":"2024-05-11T14:52:08.947768Z","shell.execute_reply":"2024-05-11T14:52:09.082263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wv_model = gensim.models.Word2Vec.load('word2vec_v2.model')","metadata":{"execution":{"iopub.status.busy":"2024-05-11T15:14:15.318068Z","iopub.execute_input":"2024-05-11T15:14:15.318460Z","iopub.status.idle":"2024-05-11T15:14:17.296420Z","shell.execute_reply.started":"2024-05-11T15:14:15.318429Z","shell.execute_reply":"2024-05-11T15:14:17.295638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wv_model.wv.most_similar(\"lula\")","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:52:16.739821Z","iopub.execute_input":"2024-05-11T14:52:16.740419Z","iopub.status.idle":"2024-05-11T14:52:16.812134Z","shell.execute_reply.started":"2024-05-11T14:52:16.740387Z","shell.execute_reply":"2024-05-11T14:52:16.811009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wv_model.wv.most_similar(\"esporte\")","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:52:20.263244Z","iopub.execute_input":"2024-05-11T14:52:20.263936Z","iopub.status.idle":"2024-05-11T14:52:20.282351Z","shell.execute_reply.started":"2024-05-11T14:52:20.263902Z","shell.execute_reply":"2024-05-11T14:52:20.280968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(wv_model.wv.key_to_index))","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:52:21.931371Z","iopub.execute_input":"2024-05-11T14:52:21.932151Z","iopub.status.idle":"2024-05-11T14:52:21.936855Z","shell.execute_reply.started":"2024-05-11T14:52:21.932119Z","shell.execute_reply":"2024-05-11T14:52:21.935971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"# Create vocabulary and embedding matrix\nmax_len = max([len(seq) for seq in articles_tokens])  # Find maximum sequence length\nvocab_size = len(wv_model.wv.key_to_index) + 1  # Include padding token (+1)\n\nembedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\nfor word, i in wv_model.wv.key_to_index.items():\n    embedding_vector = wv_model.wv[word]\n    if embedding_vector is not None:  # Handle out-of-vocabulary (OOV) words\n        embedding_matrix[i + 1] = embedding_vector  # +1 for padding token","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:54:23.057395Z","iopub.execute_input":"2024-05-11T14:54:23.058012Z","iopub.status.idle":"2024-05-11T14:54:23.628946Z","shell.execute_reply.started":"2024-05-11T14:54:23.057978Z","shell.execute_reply":"2024-05-11T14:54:23.627908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:54:25.017971Z","iopub.execute_input":"2024-05-11T14:54:25.018305Z","iopub.status.idle":"2024-05-11T14:54:25.024143Z","shell.execute_reply.started":"2024-05-11T14:54:25.018276Z","shell.execute_reply":"2024-05-11T14:54:25.023218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional, Conv1D, Dropout, MaxPooling1D, GRU\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.initializers import Constant\nfrom tensorflow.keras import regularizers","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:00:20.658060Z","iopub.execute_input":"2024-05-11T16:00:20.658943Z","iopub.status.idle":"2024-05-11T16:00:20.664660Z","shell.execute_reply.started":"2024-05-11T16:00:20.658908Z","shell.execute_reply":"2024-05-11T16:00:20.663774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# O próximo passo é tokenizar o texto\ntokenizer = Tokenizer(num_words=3000, split=\" \")\ntokenizer.fit_on_texts(df['text'].values)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T15:14:58.931315Z","iopub.execute_input":"2024-05-11T15:14:58.931981Z","iopub.status.idle":"2024-05-11T15:16:11.111693Z","shell.execute_reply.started":"2024-05-11T15:14:58.931944Z","shell.execute_reply":"2024-05-11T15:16:11.110845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transformando o texto em sequência de números e preenchendo sequência para ter o mesmo tamanho\nX_seq = tokenizer.texts_to_sequences(df['text'].values)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:59:18.514390Z","iopub.execute_input":"2024-05-11T14:59:18.515135Z","iopub.status.idle":"2024-05-11T15:00:20.054960Z","shell.execute_reply.started":"2024-05-11T14:59:18.515102Z","shell.execute_reply":"2024-05-11T15:00:20.053826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# padding our text vector so they all have the same length\nX_pad = pad_sequences(X_seq, padding=\"post\", truncating=\"post\")","metadata":{"execution":{"iopub.status.busy":"2024-05-11T15:04:04.831021Z","iopub.execute_input":"2024-05-11T15:04:04.831728Z","iopub.status.idle":"2024-05-11T15:04:07.803284Z","shell.execute_reply.started":"2024-05-11T15:04:04.831694Z","shell.execute_reply":"2024-05-11T15:04:07.802463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Categorizando as labels\nY = pd.get_dummies(df['category']).values","metadata":{"execution":{"iopub.status.busy":"2024-05-11T15:04:08.875140Z","iopub.execute_input":"2024-05-11T15:04:08.875455Z","iopub.status.idle":"2024-05-11T15:04:08.897881Z","shell.execute_reply.started":"2024-05-11T15:04:08.875430Z","shell.execute_reply":"2024-05-11T15:04:08.897141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_pad.shape)\nprint(Y.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T15:04:09.539231Z","iopub.execute_input":"2024-05-11T15:04:09.540847Z","iopub.status.idle":"2024-05-11T15:04:09.547985Z","shell.execute_reply.started":"2024-05-11T15:04:09.540810Z","shell.execute_reply":"2024-05-11T15:04:09.545265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_to_check = 'condenação'  # substitua por qualquer palavra que você queira verificar\n\n# Obtenha o índice da palavra\nindex = tokenizer.word_index.get(word_to_check)\n\nif index is not None:\n    print(f\"A palavra '{word_to_check}' está mapeada para o índice {index} no tokenizer.\")\nelse:\n    print(f\"A palavra '{word_to_check}' não está no vocabulário do tokenizer.\")","metadata":{"execution":{"iopub.status.busy":"2024-05-11T15:08:28.070157Z","iopub.execute_input":"2024-05-11T15:08:28.070503Z","iopub.status.idle":"2024-05-11T15:08:28.076526Z","shell.execute_reply.started":"2024-05-11T15:08:28.070478Z","shell.execute_reply":"2024-05-11T15:08:28.075517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Crie um mapeamento de índices para palavras\nindex_to_word = {v: k for k, v in tokenizer.word_index.items()}","metadata":{"execution":{"iopub.status.busy":"2024-05-11T15:06:56.164669Z","iopub.execute_input":"2024-05-11T15:06:56.165021Z","iopub.status.idle":"2024-05-11T15:06:56.261393Z","shell.execute_reply.started":"2024-05-11T15:06:56.164996Z","shell.execute_reply":"2024-05-11T15:06:56.260567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Escolhendo um exemplo para mostrar\nexample_index = 0\n\nsequence_to_translate = X_seq[example_index]\ntranslated_text = ' '.join(index_to_word[i] for i in sequence_to_translate if i in index_to_word)\n\nprint(\"Texto original: \", df['text'].values[example_index])\n\n# Mostrando a sequência correspondente\nprint(\"Sequência correspondente: \", X_seq[example_index])\n\n# Mostrando a sequência após o padding\nprint(\"Sequência após o padding: \", X_pad[example_index])\n\nprint(\"Texto traduzido: \", translated_text)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T15:08:36.322044Z","iopub.execute_input":"2024-05-11T15:08:36.322417Z","iopub.status.idle":"2024-05-11T15:08:36.329504Z","shell.execute_reply.started":"2024-05-11T15:08:36.322388Z","shell.execute_reply":"2024-05-11T15:08:36.328377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dividindo os dados em conjunto de treino e teste\nX_train, X_test, Y_train, Y_test = train_test_split(X_pad, Y, test_size = 0.3, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T15:09:03.349116Z","iopub.execute_input":"2024-05-11T15:09:03.350029Z","iopub.status.idle":"2024-05-11T15:09:04.076256Z","shell.execute_reply.started":"2024-05-11T15:09:03.349994Z","shell.execute_reply":"2024-05-11T15:09:04.075358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-11T15:09:06.286538Z","iopub.execute_input":"2024-05-11T15:09:06.287372Z","iopub.status.idle":"2024-05-11T15:09:06.292905Z","shell.execute_reply.started":"2024-05-11T15:09:06.287341Z","shell.execute_reply":"2024-05-11T15:09:06.291978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del articles_tokens, wv_model, tokenizer, Y, X_seq","metadata":{"execution":{"iopub.status.busy":"2024-05-11T15:16:11.113180Z","iopub.execute_input":"2024-05-11T15:16:11.113462Z","iopub.status.idle":"2024-05-11T15:16:12.364198Z","shell.execute_reply.started":"2024-05-11T15:16:11.113439Z","shell.execute_reply":"2024-05-11T15:16:12.363278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\n# Load pre-trained embeddings\nembedding_layer = Embedding(\n    vocab_size, \n    EMBEDDING_DIM, \n    embeddings_initializer=Constant(embedding_matrix), \n    trainable=True\n)\n\nmodel.add(embedding_layer)\nmodel.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\nmodel.add(MaxPooling1D(pool_size=3))\nmodel.add(Bidirectional(LSTM(32, return_sequences=True, kernel_regularizer=regularizers.l2(0.01))))\nmodel.add(Dropout(0.5))\nmodel.add(Bidirectional(LSTM(32, return_sequences=False, kernel_regularizer=regularizers.l2(0.01))))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(Y_train.shape[1], activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-05-11T22:05:03.495045Z","iopub.execute_input":"2024-05-11T22:05:03.495714Z","iopub.status.idle":"2024-05-11T22:05:03.536809Z","shell.execute_reply.started":"2024-05-11T22:05:03.495684Z","shell.execute_reply":"2024-05-11T22:05:03.535957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss = tf.keras.losses.CategoricalCrossentropy(), \n              optimizer = tf.keras.optimizers.Adam(), \n              metrics = [tf.keras.metrics.F1Score(average=\"macro\")])","metadata":{"execution":{"iopub.status.busy":"2024-05-11T22:05:03.757799Z","iopub.execute_input":"2024-05-11T22:05:03.758270Z","iopub.status.idle":"2024-05-11T22:05:03.766590Z","shell.execute_reply.started":"2024-05-11T22:05:03.758236Z","shell.execute_reply":"2024-05-11T22:05:03.765901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"earlystop = EarlyStopping(monitor='val_loss', patience=3, mode='min', restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T22:05:04.301963Z","iopub.execute_input":"2024-05-11T22:05:04.302241Z","iopub.status.idle":"2024-05-11T22:05:04.306694Z","shell.execute_reply.started":"2024-05-11T22:05:04.302217Z","shell.execute_reply":"2024-05-11T22:05:04.305740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Treinando o modelo\nbatch_size = 512\nhistory = model.fit(X_train, Y_train, epochs = 15, batch_size=batch_size, callbacks=[earlystop], validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T22:05:04.873637Z","iopub.execute_input":"2024-05-11T22:05:04.873902Z","iopub.status.idle":"2024-05-11T22:31:16.589139Z","shell.execute_reply.started":"2024-05-11T22:05:04.873879Z","shell.execute_reply":"2024-05-11T22:31:16.588277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2024-05-11T22:32:38.448709Z","iopub.execute_input":"2024-05-11T22:32:38.449099Z","iopub.status.idle":"2024-05-11T22:32:38.453663Z","shell.execute_reply.started":"2024-05-11T22:32:38.449070Z","shell.execute_reply":"2024-05-11T22:32:38.452689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotando a história de perda\nplt.figure(figsize=(12, 6))\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-11T22:32:39.087857Z","iopub.execute_input":"2024-05-11T22:32:39.088138Z","iopub.status.idle":"2024-05-11T22:32:39.459217Z","shell.execute_reply.started":"2024-05-11T22:32:39.088115Z","shell.execute_reply":"2024-05-11T22:32:39.458343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotando a história de perda\nplt.figure(figsize=(12, 6))\nplt.plot(history.history['f1_score'], label='Train Score')\nplt.plot(history.history['val_f1_score'], label='Validation Score')\nplt.title('Model F1 Score')\nplt.ylabel('F1')\nplt.xlabel('Epochs')\nplt.legend(loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-11T22:32:39.662446Z","iopub.execute_input":"2024-05-11T22:32:39.663235Z","iopub.status.idle":"2024-05-11T22:32:39.969752Z","shell.execute_reply.started":"2024-05-11T22:32:39.663206Z","shell.execute_reply":"2024-05-11T22:32:39.968815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Gerando o relatório de classificação\nY_test_pred = model.predict(X_test)\nY_test_pred_classes = np.argmax(Y_test_pred, axis=1)\nY_test_classes = np.argmax(Y_test, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T22:32:40.314200Z","iopub.execute_input":"2024-05-11T22:32:40.314487Z","iopub.status.idle":"2024-05-11T22:34:09.534651Z","shell.execute_reply.started":"2024-05-11T22:32:40.314462Z","shell.execute_reply":"2024-05-11T22:34:09.533417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(Y_test_classes, Y_test_pred_classes, target_names=df['category'].unique()))","metadata":{"execution":{"iopub.status.busy":"2024-05-11T22:34:09.543630Z","iopub.execute_input":"2024-05-11T22:34:09.543994Z","iopub.status.idle":"2024-05-11T22:34:09.596723Z","shell.execute_reply.started":"2024-05-11T22:34:09.543961Z","shell.execute_reply":"2024-05-11T22:34:09.595870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Gerar a matriz de confusão\ncm = confusion_matrix(Y_test_classes, Y_test_pred_classes)\n\n# Criar uma matriz de zeros com a mesma forma da matriz de confusão\nmask = np.zeros_like(cm)\n\n# Marcar a metade superior da matriz com True para ocultá-la\nmask[np.triu_indices_from(mask, k=1)] = True\n\n# Obter os nomes das classes\nclass_names = df['category'].unique()\n\n# Visualizar a matriz de confusão\nplt.figure(figsize=(10,7))\nsns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predito')\nplt.ylabel('Verdadeiro')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-11T22:35:28.869612Z","iopub.execute_input":"2024-05-11T22:35:28.869982Z","iopub.status.idle":"2024-05-11T22:35:29.412316Z","shell.execute_reply.started":"2024-05-11T22:35:28.869954Z","shell.execute_reply":"2024-05-11T22:35:29.411460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-05-11T22:34:10.010569Z","iopub.execute_input":"2024-05-11T22:34:10.010865Z","iopub.status.idle":"2024-05-11T22:34:10.035733Z","shell.execute_reply.started":"2024-05-11T22:34:10.010839Z","shell.execute_reply":"2024-05-11T22:34:10.034911Z"},"trusted":true},"execution_count":null,"outputs":[]}]}